<!DOCTYPE html>
<html class="full-height">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <link rel="stylesheet" href="//cdn.bootcss.com/bulma/0.4.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  
  <title>Overview of MCMC Methods (I) | What&#39;s life without whimsy?</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Why We Need MCMC MethodsUnder the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimpse">
<meta name="keywords" content="Bayesian Modeling and Inference">
<meta property="og:type" content="article">
<meta property="og:title" content="Overview of MCMC Methods (I)">
<meta property="og:url" content="http://yoursite.com/2017/12/12/Overview of MCMC Methods/index.html">
<meta property="og:site_name" content="What&#39;s life without whimsy?">
<meta property="og:description" content="Why We Need MCMC MethodsUnder the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimpse">
<meta property="og:image" content="http://yoursite.com/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png">
<meta property="og:image" content="http://yoursite.com/2017/12/12/Overview%20of%20MCMC%20Methods/adaptive_rejection.png">
<meta property="og:updated_time" content="2018-07-07T11:44:10.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Overview of MCMC Methods (I)">
<meta name="twitter:description" content="Why We Need MCMC MethodsUnder the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimpse">
<meta name="twitter:image" content="http://yoursite.com/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png">
  
    <link rel="alternate" href="/atom.xml" title="What&#39;s life without whimsy?" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/common.css">
<link rel="stylesheet" href="/css/nav.css">
<link rel="stylesheet" href="/css/layout.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><header id="navbar" class="overflow-hidden">
  <div class="container">
    <nav class="nav">
         <div class="nav-left">
            <a href="/" class="nav-item" style="font-size: 20px;">
              <span class="logo">Yuanhanqing Huang</span>'s Blog
            </a>
         </div>
        <div class="nav-center is-hidden position-relative" id="search_container">
            <div class="nav-item full-width full-height">
                <i class="fa fa-search has-padding" aria-hidden="true"></i>
                <input type="text" id="search_input" class="search-input full-height full-width" placeholder="Search post" autofocus>
                <i id="close_search" class="fa fa-times" aria-hidden="true"></i>
            </div>
            <div id="search_result"></div>
        </div>
        <div class="nav-right nav-menu">
            <a class="nav-item" id="search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
            
            <a class="nav-item" href="/">
                Home
            </a>
            
            <a class="nav-item" href="/Resume">
                Resume
            </a>
            
        </div>
        <span class="nav-toggle" id="navMenuDropdown">
            <span></span>
            <span></span>
            <span></span>
        </span>
        <div class="navbar-menu position-absolute full-width content-box is-hidden-desktop is-flex flex-column center" style="top: 100%;">
            
            <a class="nav-item flex-1" href="/">
                Home
            </a>
            
            <a class="nav-item flex-1" href="/Resume">
                Resume
            </a>
            
        </div>
    </nav>
  </div>
</header>

  <div id="main-wrap" class="position-relative" style="margin-top: 55px;">
      <div class="main-inner-content">
          <!--博文页面-->

<style>
    .header-box {
        height: 370px;
        filter: blur(10px);
        background-size: cover;
        background-color: lightsteelblue;
    }

    .post-box {
        padding: 15px;
        padding-top: 60px;
        min-height: 80vh;
        margin-top: -200px;
        border-radius: 4px;
        background-color: rgba(255,255,255,.8);
    }

    .post-avatar {
        height: 30px;
        width: 30px;
        border-radius: 50%;
    }

    .flow-chart {
        text-align: center;
    }

    img[alt="post-cover"] {
        display: none;
    }
</style>
<header>
    <div id="header_box" class="header-box"></div>
</header>
<section>
    <div class="container post-box">
        <div class="content post-title is-flex center flex-column" style="margin-bottom: 70px; overflow: auto;">
            <h1 class="has-text-centered" style="padding-bottom: 10px; border-bottom: 3px solid #fff">
                <strong>Overview of MCMC Methods (I)</strong>
            </h1>
            
            <div class="is-flex align-center">
                <img class="post-avatar" src="/img/personal_pic.jpg">
                <span style="padding:0 10px;"> <span class="sub-title">By</span> Yuanhanqing Huang</span>
                <span class="post-date sub-title">at: 2017-12-12</span>
            </div>
            
                <div>
                    
                         <a class="tag is-post-tag" href="/tags/Bayesian-Modeling-and-Inference/">Bayesian Modeling and Inference</a>
                    
                </div>
            
        </div>
        <div class="content" style="overflow: auto">
            <h1 id="Why-We-Need-MCMC-Methods"><a href="#Why-We-Need-MCMC-Methods" class="headerlink" title="Why We Need MCMC Methods"></a>Why We Need MCMC Methods</h1><p>Under the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimpse of the Bayesian equation: </p>
<script type="math/tex; mode=display">P(y_{i}|x)=\frac{P(x|y_{i})P(y_{i})}{\sum{P(x|y)P(y)}}</script><p>It is always difficult to calculate the denominator, since it is always impossible to enumerate all of the possible $y$ and corresponding $x$ from my understanding. And that’s also why Geoffrey Hinton put forward Convergence Divergence to train Boltzmann Machine. Therefore we needs methods to help us approximate the posterior. Currently there are two methods, one is variational inference, the other is Monte Carlo Markov Chain sampling methods, which is the topic for this article.<br>Under ordinary inference problem setting, when we need to figure out certain parameters, we should calculate them in the following way:  </p>
<script type="math/tex; mode=display">\theta = \int_{\theta}{\theta P(\theta|x)d\theta}</script><p>In MCMC, after sampling adequate number of samples from the posterior distribution, we could approximate the original equation in the following way:  </p>
<script type="math/tex; mode=display">\hat{E}_{\theta} =\frac{1}{n} \sum_{i=1}^{n}{\theta^{(i)}}</script><h1 id="Sampling-Methods"><a href="#Sampling-Methods" class="headerlink" title="Sampling Methods"></a>Sampling Methods</h1><h2 id="Simplest-Sampling-Methods-Inverse-of-CDF"><a href="#Simplest-Sampling-Methods-Inverse-of-CDF" class="headerlink" title="Simplest Sampling Methods: Inverse of CDF"></a>Simplest Sampling Methods: Inverse of CDF</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">u ~ U(0, 1)</div><div class="line">x = CDF_inverse(u)</div></pre></td></tr></table></figure>
<p>This sampling method is the one we see most in our undergraduate Probability class. There is a problem haunting it: all too often, it is difficult or even impossible to write out the function of CDF_inverse. This problem compels us to find a more feasible way to execute sampling.</p>
<h2 id="Rejection-Sampling"><a href="#Rejection-Sampling" class="headerlink" title="Rejection Sampling"></a>Rejection Sampling</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">while not enough samples:</div><div class="line">    x_i ~ q(x)</div><div class="line">    u ~ U(0, 1)</div><div class="line">    if u &lt; p(x_i)/(M * q(x_i)) then</div><div class="line">        accept x_i</div><div class="line">    else </div><div class="line">        reject x_i</div><div class="line">    end if</div><div class="line">end while</div></pre></td></tr></table></figure>
<img src="/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png" alt="reject_sampling.png" title="">
<p>Rejection sampling does not require knowing the function of inverse of CDF. Instead, it use a sampling function q(x), which often has a comparatively simpler form. The influence of original posterior distribution p(x) is demonstrated in the accaption-rejection judgement. When the value of fraction p(x)/Mq(x) is big, it is easier to accept this samples. However, the major problem of this method is that the frequency of rejection is much higher than that of accpetance, especially when x is of high dimension. In this case, rejection sampling is not efficient, and its adaptation is needed.<br>There exists adaptive rejection sampling, where adaptation has been done with respect to the sampling function q(x). By making q(x) approximates p(x) as close as possible, the acception rate could be improved dramatically. The illustration for this adaptation is following:<br><img src="/2017/12/12/Overview%20of%20MCMC%20Methods/adaptive_rejection.png" alt="adaptive_rejection.png" title=""><br>Note that in order to make sure that every tagent has value larger than p(x), p(x) or its transformation must be concave.  </p>
<h2 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h2><p>In importance sampling, we introduce q(x) which is comparatively easier to sample than p(x) as that in rejection sampling. Yet q(x) here has different usage. We could transform the original expectation equation into the following form:</p>
<script type="math/tex; mode=display">E[f(x)] = \int_{x}{[f(x)\frac{p(x)}{q(x)}]q(x)dx}</script><p>$q(x)$ is a new distribution function, and $f(x)\frac{p(x)}{q(x)}$  is a new target function. If we could sample a series of $x^{(i)}$ from the distribution $q(x)$. Then the original integral could be approximated by the following sum: </p>
<script type="math/tex; mode=display">E[f(x)] = \frac{1}{N}\sum_{i}{f(x^{(i)})\frac{p(x^{(i)})}{q(x^{(i)})}}</script><p>There comes a question: why is this method named “Importance Sampling”?</p>
<p>That’s because the second part of the expression of $ E[f(x)] $, $p(x^{i})/q(x^{i})$ could be regarded as the weight of $ x^{i} $. Suppose for certain $ x^{a} $, $p(x^{a})$ is big yet the sampling function $q(x^{i})$ is small. It means that under original distribution $p(x)$, $ x^{a} $ is a point that has high probability to be visited. However, under current distribution $q(x)$, $ x^{a} $ has a comparatively lower visiting probability. In order to compensate this, we assign $ x^{a} $ with a higher weight,  $p(x^{i})/q(x^{i})$. Although less likely to be sampled, once added to the sampling sets, this point will contribute greatly to the overall expectation of $f(x)$.</p>
<h2 id="Metapolis-Hastings-Algorithm"><a href="#Metapolis-Hastings-Algorithm" class="headerlink" title="Metapolis-Hastings Algorithm"></a>Metapolis-Hastings Algorithm</h2><p>To understand MH sampling, first we should have a glimpse about detailed balance. From the definition of WiKiPedia, the principle of detailed balance is formulated for kinetic systems which are decomposed into elementary processes (collisions, or steps, or elementary reactions): <strong>at equilibrium, each elementary process should be equilibrated by its reverse process</strong>.</p>
<p>From mathematical perspective, we have</p>
<script type="math/tex; mode=display">p(y) = \int_{x}p(y|x)p(x)dx</script><p>And we further could write it in the following form:</p>
<script type="math/tex; mode=display">\pi_{t}(x^{*}) = \int_{x}\pi_{t-1}K(x \to x^{*})dx</script><p>$ \pi_{t}(x^{*}) $ refers to the probability to be in the state $x^{*}$ or $p(y)$ in the former equation, and $K(x \to x^{*})$ denotes the probability to transfer from state $x$ to state $x^{*}$ or $p(y|x)$ in the former equation. We could prove that, if detailed balance is satisfied, the equation $ \pi_{t}(x^{*}) = \int_{x}\pi_{t-1}K(x \to x^{*})dx $ holds. </p>
<script type="math/tex; mode=display">\pi(x)K(x^{*}|x) = \pi(x^{*})K(x|x^{*})</script><p>Then, we get</p>
<script type="math/tex; mode=display">\int\pi(x)K(x^{*}|x)dx = \int\pi(x^{*})K(x|x^{*})dx = \pi(x^{*})\int K(x|x^{*})dx = \pi(x^{*})</script><p>The following is the pseudo-code for MH sampling.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Initialize x_0</div><div class="line">For i = 0 to N-1:</div><div class="line">	u ~ U(0, 1)</div><div class="line">	x* ~ q(x*|x_i)</div><div class="line">	if u &lt; alpha(x*) = min(1, (pi(x*)q(x|x*))/(pi(x)q(x*|x)):</div><div class="line">		x_(i+1) = x* </div><div class="line">	else:</div><div class="line">		x_(i+1) = x_i</div></pre></td></tr></table></figure></p>
<p>In order to prove that MH sampling satisfies detailed balance, we need to prove $ \pi(x)K(x^{*} \to x) = \pi(x^{*})K(x \to x^*) $ </p>
<script type="math/tex; mode=display">K(x \to x^*) = q(x^* | x) min(1, \frac{\pi (x^*) \cdot q(x^* \to x)}{\pi (x) \cdot q(x \to x^*)})</script><script type="math/tex; mode=display">\pi(x)K(x^* \to x) = min(\pi (x)q(x^{*}|x), \pi (x^{*}) q(x|x^{*})) 
= \pi(x^{*})K(x \to x^*) min(\frac{\pi (x) \cdot q(x \to x^*)}{\pi (x^*) \cdot q(x^* \to x)}, 1)</script>
        </div>
        <div class="post-reply">
            
                <!-- 来必力City版安装代码 -->
                <div id="lv-container" data-id="city" data-uid="MTAyMC8yOTE4Ni81NzUz">
                    <script type="text/javascript">
                        (function(d, s) {
                            var j, e = d.getElementsByTagName(s)[0];

                            if (typeof LivereTower === 'function') { return; }

                            j = d.createElement(s);
                            j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                            j.async = true;

                            e.parentNode.insertBefore(j, e);
                        })(document, 'script');
                    </script>
                    <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
                </div>
                <!-- City版安装代码已完成 -->
            
            
        </div>
    </div>
</section>
<script>
    // 获取第一张图, 用以当封面背景图
    var img = document.querySelectorAll('img')[1]

    if (img) {
        var header_box = document.querySelector('#header_box')
        header_box.style.backgroundImage = 'url('+ img.src +')'
    }
</script>
      </div>
  </div>
  <style>
  #footer {
    min-height: 10vh;
    background: black;
    color: #fff;
  }

  #footer a {
    color: #e1e1e1;
  }
</style>
<footer id="footer" class="has-text-centered is-flex center">
  <div class="container has-padding">
    <div>
      <div>
        <!--请您保留作者署名, 主题制作来之不易-->
        Theme by <a href="http://haojen.github.io/">Haojen Ma</a>
        <br>
        Copyright © Yuanhanqing Huang 2018
        <br>
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      </div>
    </div>
  </div>
</footer>

<script src="/js/search_core.js"></script>
<script src="/js/script.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

</body>
</html>