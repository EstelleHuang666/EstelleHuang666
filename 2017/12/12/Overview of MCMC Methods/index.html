<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Overview of MCMC Methods (I) | What&#39;s life without whimsy?</title>
  <meta name="viewport" content="width=device-width">
  <meta name="description" content="S Why We Need MCMC MethodsUnder the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimp">
<meta name="keywords" content="Bayesian Modeling and Inference">
<meta property="og:type" content="article">
<meta property="og:title" content="Overview of MCMC Methods (I)">
<meta property="og:url" content="http://yoursite.com/2017/12/12/Overview of MCMC Methods/index.html">
<meta property="og:site_name" content="What&#39;s life without whimsy?">
<meta property="og:description" content="S Why We Need MCMC MethodsUnder the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimp">
<meta property="og:image" content="http://yoursite.com/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png">
<meta property="og:image" content="http://yoursite.com/2017/12/12/Overview%20of%20MCMC%20Methods/adaptive_rejection.png">
<meta property="og:updated_time" content="2018-01-21T15:26:26.170Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Overview of MCMC Methods (I)">
<meta name="twitter:description" content="S Why We Need MCMC MethodsUnder the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimp">
<meta name="twitter:image" content="http://yoursite.com/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png">
  
    <link rel="alternative" href="/atom.xml" title="What&#39;s life without whimsy?" type="application/atom+xml">
  
  
    <link rel="icon" href="/2017-03-04_14-26-51.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="mobile-nav-panel">
	<i class="icon-reorder icon-large"></i>
</div>
<header id="header">
	<h1 class="blog-title">
		<a href="/">What&#39;s life without whimsy?</a>
	</h1>
	<nav class="nav">
		<ul>
			<li><a href="/">Home</a></li><li><a href="/resume">About Me</a></li><li><a href="/archives">Archives</a></li>
			<li><a id="nav-search-btn" class="nav-icon" title="Search"></a></li>
			<li><a href="/atom.xml" id="nav-rss-link" class="nav-icon" title="RSS Feed"></a></li>
		</ul>
	</nav>
	<div id="search-form-wrap">
		<form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
	</div>
</header>
    <div id="main">
      <article id="post-Overview of MCMC Methods" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2017/12/12/Overview of MCMC Methods/" class="article-date">
  <time datetime="2017-12-12T02:00:00.000Z" itemprop="datePublished">2017-12-12</time>
</a>
		</span>
		<span class="meta-elements author">Yuanhanqing Huang</span>
		<div class="commentscount">
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 class="article-title entry-title" itemprop="name">
      Overview of MCMC Methods (I)
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>S</p>
<h1 id="Why-We-Need-MCMC-Methods"><a href="#Why-We-Need-MCMC-Methods" class="headerlink" title="Why We Need MCMC Methods"></a>Why We Need MCMC Methods</h1><p>Under the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimpse of the Bayesian equation: </p>
<script type="math/tex; mode=display">P(y_{i}|x)=\frac{P(x|y_{i})P(y_{i})}{\sum{P(x|y)P(y)}}</script><p>It is always difficult to calculate the denominator, since it is always impossible to enumerate all of the possible $y$ and corresponding $x$ from my understanding. And that’s also why Geoffrey Hinton put forward Convergence Divergence to train Boltzmann Machine. Therefore we needs methods to help us approximate the posterior. Currently there are two methods, one is variational inference, the other is Monte Carlo Markov Chain sampling methods, which is the topic for this article.<br>Under ordinary inference problem setting, when we need to figure out certain parameters, we should calculate them in the following way:  </p>
<script type="math/tex; mode=display">\theta = \int_{\theta}{\theta P(\theta|x)d\theta}</script><p>In MCMC, after sampling adequate number of samples from the posterior distribution, we could approximate the original equation in the following way:  </p>
<script type="math/tex; mode=display">\hat{E}_{\theta} =\frac{1}{n} \sum_{i=1}^{n}{\theta^{(i)}}</script><h1 id="Sampling-Methods"><a href="#Sampling-Methods" class="headerlink" title="Sampling Methods"></a>Sampling Methods</h1><h2 id="Simplest-Sampling-Methods-Inverse-of-CDF"><a href="#Simplest-Sampling-Methods-Inverse-of-CDF" class="headerlink" title="Simplest Sampling Methods: Inverse of CDF"></a>Simplest Sampling Methods: Inverse of CDF</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">u ~ U(0, 1)</div><div class="line">x = CDF_inverse(u)</div></pre></td></tr></table></figure>
<p>This sampling method is the one we see most in our undergraduate Probability class. There is a problem haunting it: all too often, it is difficult or even impossible to write out the function of CDF_inverse. This problem compels us to find a more feasible way to execute sampling.</p>
<h2 id="Rejection-Sampling"><a href="#Rejection-Sampling" class="headerlink" title="Rejection Sampling"></a>Rejection Sampling</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">while not enough samples:</div><div class="line">    x_i ~ q(x)</div><div class="line">    u ~ U(0, 1)</div><div class="line">    if u &lt; p(x_i)/(M * q(x_i)) then</div><div class="line">        accept x_i</div><div class="line">    else </div><div class="line">        reject x_i</div><div class="line">    end if</div><div class="line">end while</div></pre></td></tr></table></figure>
<img src="/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png" alt="reject_sampling.png" title="">
<p>Rejection sampling does not require knowing the function of inverse of CDF. Instead, it use a sampling function q(x), which often has a comparatively simpler form. The influence of original posterior distribution p(x) is demonstrated in the accaption-rejection judgement. When the value of fraction p(x)/Mq(x) is big, it is easier to accept this samples. However, the major problem of this method is that the frequency of rejection is much higher than that of accpetance, especially when x is of high dimension. In this case, rejection sampling is not efficient, and its adaptation is needed.<br>There exists adaptive rejection sampling, where adaptation has been done with respect to the sampling function q(x). By making q(x) approximates p(x) as close as possible, the acception rate could be improved dramatically. The illustration for this adaptation is following:<br><img src="/2017/12/12/Overview%20of%20MCMC%20Methods/adaptive_rejection.png" alt="adaptive_rejection.png" title=""><br>Note that in order to make sure that every tagent has value larger than p(x), p(x) or its transformation must be concave.  </p>
<h2 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h2><p>In importance sampling, we introduce q(x) which is comparatively easier to sample than p(x) as that in rejection sampling. Yet q(x) here has different usage. We could transform the original expectation equation into the following form:</p>
<script type="math/tex; mode=display">E[f(x)] = \int_{x}{[f(x)\frac{p(x)}{q(x)}]q(x)dx}</script><p>$q(x)$ is a new distribution function, and $f(x)\frac{p(x)}{q(x)}$  is a new target function. If we could sample a series of $x^{(i)}$ from the distribution $q(x)$. Then the original integral could be approximated by the following sum: </p>
<script type="math/tex; mode=display">E[f(x)] = \frac{1}{N}\sum_{i}{f(x^{(i)})\frac{p(x^{(i)})}{q(x^{(i)})}}</script><p>There comes a question: why is this method named “Importance Sampling”?</p>
<p>That’s because the second part of the expression of $ E[f(x)] $, $p(x^{i})/q(x^{i})$ could be regarded as the weight of $ x^{i} $. Suppose for certain $ x^{a} $, $p(x^{a})$ is big yet the sampling function $q(x^{i})$ is small. It means that under original distribution $p(x)$, $ x^{a} $ is a point that has high probability to be visited. However, under current distribution $q(x)$, $ x^{a} $ has a comparatively lower visiting probability. In order to compensate this, we assign $ x^{a} $ with a higher weight,  $p(x^{i})/q(x^{i})$. Although less likely to be sampled, once added to the sampling sets, this point will contribute greatly to the overall expectation of $f(x)$.</p>
<h2 id="Metapolis-Hastings-Algorithm"><a href="#Metapolis-Hastings-Algorithm" class="headerlink" title="Metapolis-Hastings Algorithm"></a>Metapolis-Hastings Algorithm</h2><p>To understand MH sampling, first we should have a glimpse about detailed balance. From the definition of WiKiPedia, the principle of detailed balance is formulated for kinetic systems which are decomposed into elementary processes (collisions, or steps, or elementary reactions): <strong>at equilibrium, each elementary process should be equilibrated by its reverse process</strong>.</p>
<p>From mathematical perspective, we have</p>
<script type="math/tex; mode=display">p(y) = \int_{x}p(y|x)p(x)dx</script><p>And we further could write it in the following form:</p>
<script type="math/tex; mode=display">\pi_{t}(x^{*}) = \int_{x}\pi_{t-1}K(x \to x^{*})dx</script><p>$ \pi_{t}(x^{*}) $ refers to the probability to be in the state $x^{*}$ or $p(y)$ in the former equation, and $K(x \to x^{*})$ denotes the probability to transfer from state $x$ to state $x^{*}$ or $p(y|x)$ in the former equation. We could prove that, if detailed balance is satisfied, the equation $ \pi_{t}(x^{*}) = \int_{x}\pi_{t-1}K(x \to x^{*})dx $ holds. </p>
<script type="math/tex; mode=display">\pi(x)K(x^{*}|x) = \pi(x^{*})K(x|x^{*})</script><p>Then, we get</p>
<script type="math/tex; mode=display">\int\pi(x)K(x^{*}|x)dx = \int\pi(x^{*})K(x|x^{*})dx = \pi(x^{*})\int K(x|x^{*})dx = \pi(x^{*})</script><p>The following is the pseudo-code for MH sampling.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Initialize x_0</div><div class="line">For i = 0 to N-1:</div><div class="line">	u ~ U(0, 1)</div><div class="line">	x* ~ q(x*|x_i)</div><div class="line">	if u &lt; alpha(x*) = min(1, (pi(x*)q(x|x*))/(pi(x)q(x*|x)):</div><div class="line">		x_(i+1) = x* </div><div class="line">	else:</div><div class="line">		x_(i+1) = x_i</div></pre></td></tr></table></figure></p>
<p>In order to prove that MH sampling satisfies detailed balance, we need to prove $ \pi(x)K(x^{*} \to x) = \pi(x^{*})K(x \to x^*) $ </p>
<script type="math/tex; mode=display">K(x \to x^*) = q(x^* | x) min(1, \frac{\pi (x^*) \cdot q(x^* \to x)}{\pi (x) \cdot q(x \to x^*)})</script><script type="math/tex; mode=display">\pi(x)K(x^* \to x) = min(\pi (x)q(x^{*}|x), \pi (x^{*}) q(x|x^{*})) 
= \pi(x^{*})K(x \to x^*) min(\frac{\pi (x) \cdot q(x \to x^*)}{\pi (x^*) \cdot q(x^* \to x)}, 1)</script>
    
	</div>
	<footer class="entry-footer">
		<div class="entry-meta-footer">
			<span class="category">
				
			</span>
			<span class="tags">
				
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bayesian-Modeling-and-Inference/">Bayesian Modeling and Inference</a></li></ul>

			</span>
		</div>
	</footer>
	
    
<nav id="article-nav">
  
    <a href="/2018/01/04/Variational Inference/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Variational Inference
        
      </div>
    </a>
  
  
</nav>

  
</article>




    </div>
    <div class="mb-search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>
<footer id="footer">
	<h1 class="footer-blog-title">
		<a href="/">What&#39;s life without whimsy?</a>
	</h1>
	<span class="copyright">
		&copy; 2018 Yuanhanqing Huang<br>
		Modify from <a href="http://sanographix.github.io/tumblr/apollo/" target="_blank">Apollo</a> theme, designed by <a href="http://www.sanographix.net/" target="_blank">SANOGRAPHIX.NET</a><br>
		Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	</span>
</footer>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>