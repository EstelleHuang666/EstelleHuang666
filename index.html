<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>What&#39;s life without whimsy?</title>
  <meta name="viewport" content="width=device-width">
  <meta property="og:type" content="website">
<meta property="og:title" content="What&#39;s life without whimsy?">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="What&#39;s life without whimsy?">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="What&#39;s life without whimsy?">
  
    <link rel="alternative" href="/atom.xml" title="What&#39;s life without whimsy?" type="application/atom+xml">
  
  
    <link rel="icon" href="/2017-03-04_14-26-51.jpg">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]--><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  
</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="mobile-nav-panel">
	<i class="icon-reorder icon-large"></i>
</div>
<header id="header">
	<h1 class="blog-title">
		<a href="/">What&#39;s life without whimsy?</a>
	</h1>
	<nav class="nav">
		<ul>
			<li><a href="/">Home</a></li><li><a href="/resume">About Me</a></li><li><a href="/archives">Archives</a></li>
			<li><a id="nav-search-btn" class="nav-icon" title="Search"></a></li>
			<li><a href="/atom.xml" id="nav-rss-link" class="nav-icon" title="RSS Feed"></a></li>
		</ul>
	</nav>
	<div id="search-form-wrap">
		<form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
	</div>
</header>
    <div id="main">
      
  
    <article id="post-Understand textsum and seq2seq with Attention from TensorFlow Code" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2018/01/23/Understand textsum and seq2seq with Attention from TensorFlow Code/" class="article-date">
  <time datetime="2018-01-23T13:40:21.000Z" itemprop="datePublished">2018-01-23</time>
</a>
		</span>
		<span class="meta-elements author">Yuanhanqing Huang</span>
		<div class="commentscount">
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 itemprop="name" class="entry-title">
      <a class="article-title" href="/2018/01/23/Understand textsum and seq2seq with Attention from TensorFlow Code/">Understand textsum and seq2seq with Attention from TensorFlow Code</a>
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>This article will peel textsum algorithm and seq2seq with attention mechanism based on the project on TensorFlow/models into very little detail. (<a href="https://github.com/tensorflow/models/tree/master/research/textsum" target="_blank" rel="external">tensorflow/models/research/textsum</a>)And here is the code of my <a href="https://github.com/EstelleHuang666/textsum_tensorflow_usr" target="_blank" rel="external">personal realization</a> of seq2seq with Attention based on the official code, and it turns out to converge quite well.  </p>
<h2 id="Transfer-Text-into-bin-Type"><a href="#Transfer-Text-into-bin-Type" class="headerlink" title="Transfer Text into .bin Type"></a>Transfer Text into .bin Type</h2><p>This part is written in textsum_data_convert.py. The inputs are text file, encoded in utf-8. It has two functions.</p>
<ol>
<li>It outputs .bin file which transform the original unstructured text file into structured .bin file. </li>
<li>It outputs vocab file which counts frequncy of certain word in text files and stores the word as well as its frequency.<br>As for the first function, we have: </li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">def _convert_files_to_binary(input_filenames, output_filename):</div><div class="line">  with open(output_filename, &apos;wb&apos;) as writer:</div><div class="line">    for filename in input_filenames:</div><div class="line">      with open(filename, &apos;r&apos;) as f:</div><div class="line">        document = f.read()</div><div class="line">    </div><div class="line">      document_parts = document.split(&apos;\n&apos;, 1)</div><div class="line">      assert len(document_parts) == 2</div><div class="line">    </div><div class="line">      title = &apos;&lt;d&gt;&lt;p&gt;&lt;s&gt;&apos; + document_parts[0] + &apos;&lt;/s&gt;&lt;/p&gt;&lt;/d&gt;&apos;</div><div class="line">      # encode the title into the form of (&apos;UTF-8&apos;), otherwise in tf_example.features.feature[].bytes_list.value.extend()</div><div class="line">      # will report an error.</div><div class="line">      title = title.encode(&apos;utf8&apos;)</div><div class="line">      </div><div class="line">      # body = document_parts[1].decode(&apos;utf8&apos;).replace(&apos;\n&apos;, &apos; &apos;).replace(&apos;\t&apos;, &apos; &apos;)</div><div class="line">      # AttributeError: &apos;str&apos; object has no attribute &apos;decode&apos; -&gt; by Murphy 02.Jan.18</div><div class="line">      try:</div><div class="line">        body = document_parts[1].decode(&apos;utf8&apos;).replace(&apos;\n&apos;, &apos; &apos;).replace(&apos;\t&apos;, &apos; &apos;)</div><div class="line">      except:</div><div class="line">        body = document_parts[1].replace(&apos;\n&apos;, &apos; &apos;).replace(&apos;\t&apos;, &apos; &apos;)</div><div class="line">      sentences = sent_tokenize(body)</div><div class="line">      body = &apos;&lt;d&gt;&lt;p&gt;&apos; + &apos; &apos;.join([&apos;&lt;s&gt;&apos; + sentence + &apos;&lt;/s&gt;&apos; for sentence in sentences]) + &apos;&lt;/p&gt;&lt;/d&gt;&apos;</div><div class="line">      body = body.encode(&apos;utf8&apos;)</div><div class="line">    </div><div class="line">      tf_example = example_pb2.Example()</div><div class="line">      tf_example.features.feature[&apos;article&apos;].bytes_list.value.extend([body])</div><div class="line">      tf_example.features.feature[&apos;abstract&apos;].bytes_list.value.extend([title])</div><div class="line">      tf_example_str = tf_example.SerializeToString()</div><div class="line">      str_len = len(tf_example_str)</div><div class="line">      writer.write(struct.pack(&apos;q&apos;, str_len))</div><div class="line">      writer.write(struct.pack(&apos;%ds&apos; % str_len, tf_example_str))</div></pre></td></tr></table></figure>
<p>It processes all the text files under the path “./data/cnn/stories”. These text files are consist of two parts, “title” and “body” (also known as “abstract” and “article”), which are seperated by the first “\n”. For title and body, both of them are decorated with prefix &lt;\d&gt;&lt;\p&gt;&lt;\s&gt; and postfix &lt;/\s&gt;&lt;/\p&gt;&lt;/\d&gt;. Moreover, body part is seperated into sentences by the fucntion sent_tokenize from nltk package. Every sentence in body is decorated with prefix &lt;\s&gt; and postfix &lt;/\s&gt;. The “/n”s in body are replaced by “/t”s. Then, the processed “title” and “body” are writen into text file through the format of example_pb2.Example(), which is a format imported from tensorflow.core.example. It can simply be preceived as a storing format without special meaning. If you like, you could write your own format to replace example_pb2.Example().</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">def _text_to_vocabulary(input_directories, vocabulary_filename, max_words=200000):</div><div class="line">  filenames = _get_filenames(input_directories)</div><div class="line">    </div><div class="line">  counter = collections.Counter()</div><div class="line">    </div><div class="line">  for filename in filenames:</div><div class="line">    with open(filename, &apos;r&apos;) as f:</div><div class="line">      document = f.read()</div><div class="line">    </div><div class="line">    words = document.split()</div><div class="line">    counter.update(words)</div><div class="line"></div><div class="line">  with open(vocabulary_filename, &apos;w&apos;) as writer:</div><div class="line">    for word, count in counter.most_common(max_words - 2):</div><div class="line">      writer.write(word + &apos; &apos; + str(count) + &apos;\n&apos;)</div><div class="line">    writer.write(&apos;&lt;s&gt; 0\n&apos;)</div><div class="line">    writer.write(&apos;&lt;/s&gt; 0\n&apos;)</div><div class="line">    writer.write(&apos;&lt;UNK&gt; 0\n&apos;)</div><div class="line">    writer.write(&apos;&lt;PAD&gt; 0\n&apos;)</div></pre></td></tr></table></figure>
<p>collections.Counter() works as a collector (or you can see as a dictionary) in the format of {“word1”: frequency1 , “word2”: frequency2 ,…}. By executing “.update” operation and pass a list of words into the Counter, you could let this class automatically update the word-frequency dictionary. At the end, it adds some symbols with special meaning to the Counter. (&lt;\s&gt; &lt;/\s&gt; denote the start and the end of a sentence; <pad> is used to padding the blank to make all of the sentences have same length) </pad></p>
<h2 id="batcher-reader-management-of-input-data"><a href="#batcher-reader-management-of-input-data" class="headerlink" title="batcher_reader: management of input data"></a>batcher_reader: management of input data</h2><p>First, let’s have a glance of the major part of function main:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">vocab = data.Vocab(FLAGS.vocab_path, 1000000)</div><div class="line">  # Check for presence of required special tokens.</div><div class="line">  assert vocab.CheckVocab(data.PAD_TOKEN) &gt; 0</div><div class="line">  assert vocab.CheckVocab(data.UNKNOWN_TOKEN) &gt;= 0</div><div class="line">  assert vocab.CheckVocab(data.SENTENCE_START) &gt; 0</div><div class="line">  assert vocab.CheckVocab(data.SENTENCE_END) &gt; 0</div><div class="line"></div><div class="line">  batch_size = 4</div><div class="line">  if FLAGS.mode == &apos;decode&apos;:</div><div class="line">    batch_size = FLAGS.beam_size</div><div class="line"></div><div class="line">  hps = seq2seq_attention_model.HParams(</div><div class="line">      mode=FLAGS.mode,  # train, eval, decode</div><div class="line">      min_lr=0.001,  # min learning rate.</div><div class="line">      lr=0.015,  # learning rate</div><div class="line">      batch_size=batch_size,</div><div class="line">      enc_layers=1,</div><div class="line">      enc_timesteps=800,</div><div class="line">      dec_timesteps=50,</div><div class="line">      min_input_len=2,  # discard articles/summaries &lt; than this</div><div class="line">      num_hidden=256,  # for rnn cell</div><div class="line">      emb_dim=128,  # If 0, don&apos;t use embedding</div><div class="line">      max_grad_norm=2,</div><div class="line">      num_softmax_samples=4096)  # If 0, no sampled softmax.</div><div class="line"></div><div class="line">  batcher = batch_reader.Batcher(</div><div class="line">      FLAGS.data_path, vocab, hps, FLAGS.article_key,</div><div class="line">      FLAGS.abstract_key, FLAGS.max_article_sentences,</div><div class="line">      FLAGS.max_abstract_sentences, bucketing=FLAGS.use_bucketing,</div><div class="line">      truncate_input=FLAGS.truncate_input)</div><div class="line">  tf.set_random_seed(FLAGS.random_seed)</div><div class="line"></div><div class="line">  if hps.mode == &apos;train&apos;:</div><div class="line">    model = seq2seq_attention_model.Seq2SeqAttentionModel(</div><div class="line">        hps, vocab, num_gpus=FLAGS.num_gpus)</div><div class="line">    _Train(model, batcher)</div><div class="line">  elif hps.mode == &apos;eval&apos;:</div><div class="line">    model = seq2seq_attention_model.Seq2SeqAttentionModel(</div><div class="line">        hps, vocab, num_gpus=FLAGS.num_gpus)</div><div class="line">    _Eval(model, batcher, vocab=vocab)</div><div class="line">  elif hps.mode == &apos;decode&apos;:</div><div class="line">    decode_mdl_hps = hps</div><div class="line">    # Only need to restore the 1st step and reuse it since</div><div class="line">    # we keep and feed in state for each step&apos;s output.</div><div class="line">    decode_mdl_hps = hps._replace(dec_timesteps=1)</div><div class="line">    model = seq2seq_attention_model.Seq2SeqAttentionModel(</div><div class="line">        decode_mdl_hps, vocab, num_gpus=FLAGS.num_gpus)</div><div class="line">    decoder = seq2seq_attention_decode.BSDecoder(model, batcher, hps, vocab)</div><div class="line">    decoder.DecodeLoop()</div></pre></td></tr></table></figure></p>
<p>We can see that main function do the following steps:</p>
<ol>
<li>read in hyperparameters;</li>
<li>use batch_reader to manage the data;</li>
<li>execute training/evaluating/decoding process.</li>
</ol>
<p>For batch_reader, it only contains one class: Batcher. It has following methods:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">class Batcher(object):</div><div class="line">	def NextBatch(self):</div><div class="line"></div><div class="line">	def _FillInputQueue(self):</div><div class="line"></div><div class="line">	def _FillBucketInputQueue(self):</div><div class="line"></div><div class="line">	def _WatchThreads(self):</div><div class="line"></div><div class="line">	def _TextGenerator(self, example_gen):</div><div class="line"></div><div class="line">	def _GetExFeatureText(self, ex, key):</div><div class="line"></div></pre></td></tr></table></figure></p>
<p>We are gonna to dissect these code one by one:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line">def _FillInputQueue(self):</div><div class="line">	&quot;&quot;&quot;Fill input queue with ModelInput.&quot;&quot;&quot;</div><div class="line">	start_id = self._vocab.WordToId(data.SENTENCE_START)</div><div class="line">	end_id = self._vocab.WordToId(data.SENTENCE_END)</div><div class="line">	pad_id = self._vocab.WordToId(data.PAD_TOKEN)</div><div class="line">	input_gen = self._TextGenerator(data.ExampleGen(self._data_path))</div><div class="line">	while True:</div><div class="line">	  (article, abstract) = six.next(input_gen)</div><div class="line">	  article_sentences = [sent.strip() for sent in</div><div class="line">	                       data.ToSentences(article.decode(&apos;utf-8&apos;), include_token=False)]</div><div class="line">	  abstract_sentences = [sent.strip() for sent in</div><div class="line">	                        data.ToSentences(abstract.decode(&apos;utf-8&apos;), include_token=False)]</div><div class="line"></div><div class="line">	  enc_inputs = []</div><div class="line">	  # Use the &lt;s&gt; as the &lt;GO&gt; symbol for decoder inputs.</div><div class="line">	  dec_inputs = [start_id]</div><div class="line"></div><div class="line">	  # Convert first N sentences to word IDs, stripping existing &lt;s&gt; and &lt;/s&gt;.</div><div class="line">	  for i in xrange(min(self._max_article_sentences,</div><div class="line">	                      len(article_sentences))):</div><div class="line">	    enc_inputs += data.GetWordIds(article_sentences[i], self._vocab)</div><div class="line">	  for i in xrange(min(self._max_abstract_sentences,</div><div class="line">	                      len(abstract_sentences))):</div><div class="line">	    dec_inputs += data.GetWordIds(abstract_sentences[i], self._vocab)</div><div class="line"></div><div class="line">	  # Filter out too-short input</div><div class="line">	  if (len(enc_inputs) &lt; self._hps.min_input_len or</div><div class="line">	      len(dec_inputs) &lt; self._hps.min_input_len):</div><div class="line">	    tf.logging.warning(&apos;Drop an example - too short.\nenc:%d\ndec:%d&apos;,</div><div class="line">	                       len(enc_inputs), len(dec_inputs))</div><div class="line">	    continue</div><div class="line"></div><div class="line">	  # If we&apos;re not truncating input, throw out too-long input</div><div class="line">	  if not self._truncate_input:</div><div class="line">	    if (len(enc_inputs) &gt; self._hps.enc_timesteps or</div><div class="line">	        len(dec_inputs) &gt; self._hps.dec_timesteps):</div><div class="line">	      tf.logging.warning(&apos;Drop an example - too long.\nenc:%d\ndec:%d&apos;,</div><div class="line">	                         len(enc_inputs), len(dec_inputs))</div><div class="line">	      continue</div><div class="line">	  # If we are truncating input, do so if necessary</div><div class="line">	  else:</div><div class="line">	    if len(enc_inputs) &gt; self._hps.enc_timesteps:</div><div class="line">	      enc_inputs = enc_inputs[:self._hps.enc_timesteps]</div><div class="line">	    if len(dec_inputs) &gt; self._hps.dec_timesteps:</div><div class="line">	      dec_inputs = dec_inputs[:self._hps.dec_timesteps]</div><div class="line"></div><div class="line">	  # targets is dec_inputs without &lt;s&gt; at beginning, plus &lt;/s&gt; at end</div><div class="line">	  targets = dec_inputs[1:]</div><div class="line">	  targets.append(end_id)</div><div class="line"></div><div class="line">	  # Now len(enc_inputs) should be &lt;= enc_timesteps, and</div><div class="line">	  # len(targets) = len(dec_inputs) should be &lt;= dec_timesteps</div><div class="line"></div><div class="line">	  enc_input_len = len(enc_inputs)</div><div class="line">	  dec_output_len = len(targets)</div><div class="line"></div><div class="line">	  # Pad if necessary</div><div class="line">	  while len(enc_inputs) &lt; self._hps.enc_timesteps:</div><div class="line">	    enc_inputs.append(pad_id)</div><div class="line">	  while len(dec_inputs) &lt; self._hps.dec_timesteps:</div><div class="line">	    dec_inputs.append(end_id)</div><div class="line">	  while len(targets) &lt; self._hps.dec_timesteps:</div><div class="line">	    targets.append(end_id)</div><div class="line"></div><div class="line">	  element = ModelInput(enc_inputs, dec_inputs, targets, enc_input_len,</div><div class="line">	                       dec_output_len, &apos; &apos;.join(article_sentences),</div><div class="line">	                       &apos; &apos;.join(abstract_sentences))</div><div class="line">	  self._input_queue.put(element)</div></pre></td></tr></table></figure></p>
<p>self._vocab is a class defined in data.py. To understand it briefly, you can view it as composed of two dictionary: _word_to_id and _id_to_word. In addition, this class provides methods related to “word to id” and “id to word” processes. As for self._TextGenerator method, it uses yield instead of return to deal with the huge memory usage. To master yield, you must understand that when you call the function, the code you have written in the function body does not run. The function only returns the generator object. To understand better, please refer to <a href="https://pythontips.com/2013/09/29/the-python-yield-keyword-explained/" target="_blank" rel="external">this article</a>. </p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">def _TextGenerator(self, example_gen):</div><div class="line">	&quot;&quot;&quot;Generates article and abstract text from tf.Example.&quot;&quot;&quot;</div><div class="line">	while True:</div><div class="line">	  e = six.next(example_gen)</div><div class="line">	  try:</div><div class="line">	    article_text = self._GetExFeatureText(e, self._article_key) //return ex.features.feature[key].bytes_list.value[0]</div><div class="line">	    abstract_text = self._GetExFeatureText(e, self._abstract_key)</div><div class="line">	  except ValueError:</div><div class="line">	    tf.logging.error(&apos;Failed to get article or abstract from example&apos;)</div><div class="line">	    continue</div><div class="line"></div><div class="line">	  yield (article_text, abstract_text)</div></pre></td></tr></table></figure>
<p>six.next(example_gen) generates a tf.Example type if data of the following sample format. It’s long, but you only need to have a glanpse of its basic format.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">features &#123;</div><div class="line">  feature &#123;</div><div class="line">    key: &quot;abstract&quot;</div><div class="line">    value &#123;</div><div class="line">      bytes_list &#123;</div><div class="line">        value: &quot;&lt;d&gt;&lt;p&gt;&lt;s&gt;(CNN) -- Republican presidential contender Michele Bachmann defended her position on gay rights, the HPV vaccine and the debt ceiling as she made her debut on \&quot;The Tonight Show with Jay Leno.\&quot;&lt;/s&gt;&lt;/p&gt;&lt;/d&gt;&quot;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">  feature &#123;</div><div class="line">    key: &quot;article&quot;</div><div class="line">    value &#123;</div><div class="line">      bytes_list &#123;</div><div class="line">        value: &quot;&lt;d&gt;&lt;p&gt;&lt;s&gt; Bachmann has more usually been the butt of Leno\&apos;s jokes -- a point he made as he thanked her for being a good sport.&lt;/s&gt; &lt;s&gt;\&quot;We\&apos;ve done a million jokes.&lt;/s&gt; &lt;s&gt;Hopefully, you haven\&apos;t been ... watching any of them,\&quot; he said, as she joined him on set.&lt;/s&gt; &lt;s&gt;But Leno largely skipped the jokes Friday as he quizzed the Minnesota congresswoman on her political positions.&lt;/s&gt; &lt;s&gt;First up was the issue of the HPV vaccine, a subject on which Bachmann hit fellow Republican contender and Texas Gov.&lt;/s&gt; &lt;s&gt;Rick Perry hard in this week\&apos;s CNN/Tea Party Republican Debate.&lt;/s&gt; &lt;s&gt;Perry signed an executive order in 2007 that required Texas schoolgirls to receive vaccinations against the sexually transmitted HPV, although it wasn\&apos;t implemented.&lt;/s&gt; &lt;s&gt;Bachmann told Leno that Perry\&apos;s action had been \&quot;an abuse of executive power\&quot; and had sparked concern over \&quot;crony capitalism,\&quot; an apparent reference to the fact that a former Perry aide was a top lobbyist for Merck, the manufacturer for the HPV vaccine.&lt;/s&gt; &lt;s&gt;Merck donated to Perry\&apos;s campaign fund.&lt;/s&gt; &lt;s&gt;She added: \&quot;The concern is that there\&apos;s, you know, potentially side effects that can come with something like that.&lt;/s&gt; &lt;s&gt;But it gives a false sense of assurance to a young woman when she has that that if she\&apos;s sexually active that she doesn\&apos;t have to worry about sexually transmitted diseases.\&quot;&lt;/s&gt; &lt;s&gt;Leno responded: \&quot;Well, I don\&apos;t know if it gives assurance.&lt;/s&gt; &lt;s&gt;It can prevent cervical cancer; correct?\&quot;&lt;/s&gt; &lt;s&gt;He then pressed Bachmann over comments she made earlier this week in which she said a woman had approached the congresswoman to say her daughter had suffered \&quot;mental retardation\&quot; as a result of receiving the vaccination.&lt;/s&gt; &lt;s&gt;There had been no recorded cases of such side effects despite 30 million people receiving the jab, Leno pointed out.&lt;/s&gt; &lt;s&gt;\&quot;I wasn\&apos;t speaking as a doctor.&lt;/s&gt; &lt;s&gt;I wasn\&apos;t speaking as a scientist.&lt;/s&gt; &lt;s&gt;I was just relating what this woman said,\&quot; Bachmann replied.&lt;/s&gt; &lt;s&gt;The former tax attorney and mother of five, who won the Iowa straw poll last month but has seen her poll ratings slide since Perry entered the race, also defended two clinics she runs with her husband, offering what she said was a Christian counseling service.&lt;/s&gt; &lt;s&gt;The clinics have come under fire over claims they use a controversial therapy that encourages gay and lesbian patients to change their sexual orientation.&lt;/s&gt; &lt;s&gt;Asking Bachmann why gay people shouldn\&apos;t have the right to be happily married, Leno said: \&quot;That whole \&apos;pray the gay away\&apos; thing, What?&lt;/s&gt; &lt;s&gt;I don\&apos;t get that.\&quot;&lt;/s&gt; &lt;s&gt;Bachmann said the clinics did not discriminate, but repeated her position that marriage should be between a man and a woman.&lt;/s&gt; &lt;s&gt;Quizzed on her opposition to raising the debt ceiling, Bachmann said she would have taken the same position whether it had been President Barack Obama or George W. Bush in power.&lt;/s&gt; &lt;s&gt;On Afghanistan, Bachmann failed to answer whether she thought American forces should withdraw, but paid tribute to the \&quot;unbelievable job\&quot; done by U.S. service men and women there.&lt;/s&gt; &lt;s&gt;Leno\&apos;s final question was whom Bachmann would pick as a running mate if she wins the Republican nomination, suggesting she might want someone more moderate to balance her views.&lt;/s&gt; &lt;s&gt;She joked: \&quot;Well, you\&apos;re taken.&lt;/s&gt; &lt;s&gt;You don\&apos;t want a cut in pay, so what can I say?\&quot;&lt;/s&gt; &lt;s&gt;Leno replied: \&quot;Well, we\&apos;d probably have an argument over that gay thing.\&quot;&lt;/s&gt; &lt;s&gt;@highlight  Bachmann continues her criticism of Rick Perry over the HPV vaccine  @highlight  Leno presses Bachmann on gay marriage and the counseling clinics she runs  @highlight  The presidential hopeful says her opposition to raising the debt ceiling was not political  @highlight  Bachmann declines to say who her running mate would be&lt;/s&gt;&lt;/p&gt;&lt;/d&gt;&quot;</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

    
	</div>
	<footer class="entry-footer">
		<div class="entry-meta-footer">
			<span class="category">
				
			</span>
			<span class="tags">
				
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Neural-Network-TensorFlow/">Neural Network, TensorFlow</a></li></ul>

			</span>
		</div>
	</footer>
	
</article>


	<hr class="article-devider">



  
    <article id="post-Variational Inference" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2018/01/04/Variational Inference/" class="article-date">
  <time datetime="2018-01-04T05:08:11.000Z" itemprop="datePublished">2018-01-04</time>
</a>
		</span>
		<span class="meta-elements author">Yuanhanqing Huang</span>
		<div class="commentscount">
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 itemprop="name" class="entry-title">
      <a class="article-title" href="/2018/01/04/Variational Inference/">Variational Inference</a>
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<p>Variational Bayesian methods are a family of techniques for approximating intractable integrals arising in Bayesian inference and machine learning. They are typically used in complex statistical models consisting of observed variables (usually termed “data”) as well as unknown parameters and latent variables, with various sorts of relationships among the three types of random variables, as might be described by a graphical model. As is typical in Bayesian inference, the parameters and latent variables are grouped together as “unobserved variables”. Variational Bayesian methods are primarily used for two purposes:</p>
<ol>
<li>To provide an analytical approximation to the posterior probability of the unobserved variables, in order to do statistical inference over these variables.</li>
<li>To derive a lower bound for the marginal likelihood (sometimes called the “evidence”) of the observed data (i.e. the marginal probability of the data given the model, with marginalization performed over unobserved variables). This is typically used for performing model selection, the general idea being that a higher marginal likelihood for a given model indicates a better fit of the data by that model and hence a greater probability that the model in question was the one that generated the data. (See also the Bayes factor article.)</li>
</ol>

    
	</div>
	<footer class="entry-footer">
		<div class="entry-meta-footer">
			<span class="category">
				
			</span>
			<span class="tags">
				
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bayesian-Modeling-and-Inference/">Bayesian Modeling and Inference</a></li></ul>

			</span>
		</div>
	</footer>
	
</article>


	<hr class="article-devider">



  
    <article id="post-Overview of MCMC Methods" class="post">
	<footer class="entry-meta-header">
		<span class="meta-elements date">
			<a href="/2017/12/12/Overview of MCMC Methods/" class="article-date">
  <time datetime="2017-12-12T02:00:00.000Z" itemprop="datePublished">2017-12-12</time>
</a>
		</span>
		<span class="meta-elements author">Yuanhanqing Huang</span>
		<div class="commentscount">
			
		</div>
	</footer>
	
	<header class="entry-header">
		
  
    <h1 itemprop="name" class="entry-title">
      <a class="article-title" href="/2017/12/12/Overview of MCMC Methods/">Overview of MCMC Methods (I)</a>
    </h1>
  

	</header>
	<div class="entry-content">
		
    	<h1 id="Why-We-Need-MCMC-Methods"><a href="#Why-We-Need-MCMC-Methods" class="headerlink" title="Why We Need MCMC Methods"></a>Why We Need MCMC Methods</h1><p>Under the Bayesian problem setting, all too often, it is difficult to figure out the real posterior distribtuion. To understand this difficulty, we could firstly have a glimpse of the Bayesian equation: </p>
<script type="math/tex; mode=display">P(y_{i}|x)=\frac{P(x|y_{i})P(y_{i})}{\sum{P(x|y)P(y)}}</script><p>It is always difficult to calculate the denominator, since it is always impossible to enumerate all of the possible $y$ and corresponding $x$ from my understanding. And that’s also why Geoffrey Hinton put forward Convergence Divergence to train Boltzmann Machine. Therefore we needs methods to help us approximate the posterior. Currently there are two methods, one is variational inference, the other is Monte Carlo Markov Chain sampling methods, which is the topic for this article.<br>Under ordinary inference problem setting, when we need to figure out certain parameters, we should calculate them in the following way:  </p>
<script type="math/tex; mode=display">\theta = \int_{\theta}{\theta P(\theta|x)d\theta}</script><p>In MCMC, after sampling adequate number of samples from the posterior distribution, we could approximate the original equation in the following way:  </p>
<script type="math/tex; mode=display">\hat{E}_{\theta} =\frac{1}{n} \sum_{i=1}^{n}{\theta^{(i)}}</script><h1 id="Sampling-Methods"><a href="#Sampling-Methods" class="headerlink" title="Sampling Methods"></a>Sampling Methods</h1><h2 id="Simplest-Sampling-Methods-Inverse-of-CDF"><a href="#Simplest-Sampling-Methods-Inverse-of-CDF" class="headerlink" title="Simplest Sampling Methods: Inverse of CDF"></a>Simplest Sampling Methods: Inverse of CDF</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">u ~ U(0, 1)</div><div class="line">x = CDF_inverse(u)</div></pre></td></tr></table></figure>
<p>This sampling method is the one we see most in our undergraduate Probability class. There is a problem haunting it: all too often, it is difficult or even impossible to write out the function of CDF_inverse. This problem compels us to find a more feasible way to execute sampling.</p>
<h2 id="Rejection-Sampling"><a href="#Rejection-Sampling" class="headerlink" title="Rejection Sampling"></a>Rejection Sampling</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">while not enough samples:</div><div class="line">    x_i ~ q(x)</div><div class="line">    u ~ U(0, 1)</div><div class="line">    if u &lt; p(x_i)/(M * q(x_i)) then</div><div class="line">        accept x_i</div><div class="line">    else </div><div class="line">        reject x_i</div><div class="line">    end if</div><div class="line">end while</div></pre></td></tr></table></figure>
<img src="/2017/12/12/Overview%20of%20MCMC%20Methods/reject_sampling.png" alt="reject_sampling.png" title="">
<p>Rejection sampling does not require knowing the function of inverse of CDF. Instead, it use a sampling function q(x), which often has a comparatively simpler form. The influence of original posterior distribution p(x) is demonstrated in the accaption-rejection judgement. When the value of fraction p(x)/Mq(x) is big, it is easier to accept this samples. However, the major problem of this method is that the frequency of rejection is much higher than that of accpetance, especially when x is of high dimension. In this case, rejection sampling is not efficient, and its adaptation is needed.<br>There exists adaptive rejection sampling, where adaptation has been done with respect to the sampling function q(x). By making q(x) approximates p(x) as close as possible, the acception rate could be improved dramatically. The illustration for this adaptation is following:<br><img src="/2017/12/12/Overview%20of%20MCMC%20Methods/adaptive_rejection.png" alt="adaptive_rejection.png" title=""><br>Note that in order to make sure that every tagent has value larger than p(x), p(x) or its transformation must be concave.  </p>
<h2 id="Importance-Sampling"><a href="#Importance-Sampling" class="headerlink" title="Importance Sampling"></a>Importance Sampling</h2><p>In importance sampling, we introduce q(x) which is comparatively easier to sample than p(x) as that in rejection sampling. Yet q(x) here has different usage. We could transform the original expectation equation into the following form:</p>
<script type="math/tex; mode=display">E[f(x)] = \int_{x}{[f(x)\frac{p(x)}{q(x)}]q(x)dx}</script><p>$q(x)$ is a new distribution function, and $f(x)\frac{p(x)}{q(x)}$  is a new target function. If we could sample a series of $x^{(i)}$ from the distribution $q(x)$. Then the original integral could be approximated by the following sum: </p>
<script type="math/tex; mode=display">E[f(x)] = \frac{1}{N}\sum_{i}{f(x^{(i)})\frac{p(x^{(i)})}{q(x^{(i)})}}</script><p>There comes a question: why is this method named “Importance Sampling”?</p>
<p>That’s because the second part of the expression of $ E[f(x)] $, $p(x^{i})/q(x^{i})$ could be regarded as the weight of $ x^{i} $. Suppose for certain $ x^{a} $, $p(x^{a})$ is big yet the sampling function $q(x^{i})$ is small. It means that under original distribution $p(x)$, $ x^{a} $ is a point that has high probability to be visited. However, under current distribution $q(x)$, $ x^{a} $ has a comparatively lower visiting probability. In order to compensate this, we assign $ x^{a} $ with a higher weight,  $p(x^{i})/q(x^{i})$. Although less likely to be sampled, once added to the sampling sets, this point will contribute greatly to the overall expectation of $f(x)$.</p>
<h2 id="Metapolis-Hastings-Algorithm"><a href="#Metapolis-Hastings-Algorithm" class="headerlink" title="Metapolis-Hastings Algorithm"></a>Metapolis-Hastings Algorithm</h2><p>To understand MH sampling, first we should have a glimpse about detailed balance. From the definition of WiKiPedia, the principle of detailed balance is formulated for kinetic systems which are decomposed into elementary processes (collisions, or steps, or elementary reactions): <strong>at equilibrium, each elementary process should be equilibrated by its reverse process</strong>.</p>
<p>From mathematical perspective, we have</p>
<script type="math/tex; mode=display">p(y) = \int_{x}p(y|x)p(x)dx</script><p>And we further could write it in the following form:</p>
<script type="math/tex; mode=display">\pi_{t}(x^{*}) = \int_{x}\pi_{t-1}K(x \to x^{*})dx</script><p>$ \pi_{t}(x^{*}) $ refers to the probability to be in the state $x^{*}$ or $p(y)$ in the former equation, and $K(x \to x^{*})$ denotes the probability to transfer from state $x$ to state $x^{*}$ or $p(y|x)$ in the former equation. We could prove that, if detailed balance is satisfied, the equation $ \pi_{t}(x^{*}) = \int_{x}\pi_{t-1}K(x \to x^{*})dx $ holds. </p>
<script type="math/tex; mode=display">\pi(x)K(x^{*}|x) = \pi(x^{*})K(x|x^{*})</script><p>Then, we get</p>
<script type="math/tex; mode=display">\int\pi(x)K(x^{*}|x)dx = \int\pi(x^{*})K(x|x^{*})dx = \pi(x^{*})\int K(x|x^{*})dx = \pi(x^{*})</script><p>The following is the pseudo-code for MH sampling.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Initialize x_0</div><div class="line">For i = 0 to N-1:</div><div class="line">	u ~ U(0, 1)</div><div class="line">	x* ~ q(x*|x_i)</div><div class="line">	if u &lt; alpha(x*) = min(1, (pi(x*)q(x|x*))/(pi(x)q(x*|x)):</div><div class="line">		x_(i+1) = x* </div><div class="line">	else:</div><div class="line">		x_(i+1) = x_i</div></pre></td></tr></table></figure></p>
<p>In order to prove that MH sampling satisfies detailed balance, we need to prove $ \pi(x)K(x^{*} \to x) = \pi(x^{*})K(x \to x^*) $ </p>
<script type="math/tex; mode=display">K(x \to x^*) = q(x^* | x) min(1, \frac{\pi (x^*) \cdot q(x^* \to x)}{\pi (x) \cdot q(x \to x^*)})</script><script type="math/tex; mode=display">\pi(x)K(x^* \to x) = min(\pi (x)q(x^{*}|x), \pi (x^{*}) q(x|x^{*})) 
= \pi(x^{*})K(x \to x^*) min(\frac{\pi (x) \cdot q(x \to x^*)}{\pi (x^*) \cdot q(x^* \to x)}, 1)</script>
    
	</div>
	<footer class="entry-footer">
		<div class="entry-meta-footer">
			<span class="category">
				
			</span>
			<span class="tags">
				
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Bayesian-Modeling-and-Inference/">Bayesian Modeling and Inference</a></li></ul>

			</span>
		</div>
	</footer>
	
</article>


	<hr class="article-devider">



  
  

    </div>
    <div class="mb-search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>
<footer id="footer">
	<h1 class="footer-blog-title">
		<a href="/">What&#39;s life without whimsy?</a>
	</h1>
	<span class="copyright">
		&copy; 2018 Yuanhanqing Huang<br>
		Modify from <a href="http://sanographix.github.io/tumblr/apollo/" target="_blank">Apollo</a> theme, designed by <a href="http://www.sanographix.net/" target="_blank">SANOGRAPHIX.NET</a><br>
		Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	</span>
</footer>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]]}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>